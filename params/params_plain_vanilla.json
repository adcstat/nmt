{
    "vocab_size": 32000,
    "max_length": 200,
    "tokens_per_batch": 20000,
    "epochs": 25,
    "tokens_per_opt_step": 400000,
    "d_model": 1024,
    "n_heads": 16,
    "d_ff": 4096,
    "n_layers": 6,
    "dropout": 0.3,
    "warmup_steps": 4000,
    "max_lr": 0.001
}