{
    "vocab_size": 20000,
    "max_length": 100,
    "tokens_per_batch": 100,
    "epochs": 3,
    "grad_accumulation": 1,
    "d_model": 1,
    "n_heads": 1,
    "d_ff": 1,
    "n_layers": 1,
    "dropout": 0.0
}