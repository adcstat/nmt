{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python standard\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# huggingface\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "# torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "from torchmetrics.functional.text import sacre_bleu_score\n",
    "\n",
    "# custom\n",
    "from utils import decoding_utils, data_utils, transformer_utils as tfu\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"params.json\", \"r\") as fp:\n",
    "    params = json.load(fp)\n",
    "\n",
    "PAD_IDX = params[\"PAD_IDX\"]\n",
    "vocab_size = params[\"vocab_size\"]\n",
    "tokens_per_batch = params[\"tokens_per_batch\"]\n",
    "epochs = params[\"epochs\"]\n",
    "grad_accumulation = params[\"grad_accumulation\"]\n",
    "d_model = params[\"d_model\"]\n",
    "n_heads = params[\"n_heads\"]\n",
    "d_ff = params[\"d_ff\"]\n",
    "n_layers = params[\"n_layers\"]\n",
    "dropout = params[\"dropout\"]\n",
    "\n",
    "with open(\"wmt14.json\", \"r\") as fp:\n",
    "    wmt14 = json.load(fp)\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"bpe_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [[src, tgt] for src, tgt, _ in wmt14[\"test\"]]\n",
    "test_dataloader = DataLoader(test_data, batch_size=512, collate_fn=data_utils.collate_fn, pin_memory=True, shuffle=False)\n",
    "\n",
    "model = tfu.Transformer(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=d_model,\n",
    "    n_heads=n_heads,\n",
    "    d_ff=d_ff,\n",
    "    n_encoder_layers=n_layers,\n",
    "    n_decoder_layers=n_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "path = \"drive/MyDrive/nmt/snapshot.tar\"\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['MODEL_STATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu, preds = decoding_utils.get_bleu_score(tokenizer, model, test_dataloader, 3, DEVICE)\n",
    "bleu.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_numpy = np.array(test_data)\n",
    "test_data_numpy = test_data_numpy.transpose((1, 0))\n",
    "df = pd.DataFrame(dict(src=test_data_numpy[0], pred=preds, tgt=test_data_numpy[1]))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
